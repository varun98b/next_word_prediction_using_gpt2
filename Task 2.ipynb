{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c29a84",
   "metadata": {},
   "source": [
    "# NAME: VARUN KUMAR BHOGOJU\n",
    "# WSU ID: J893G242"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdda503a",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212df642",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e2dc52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading https://files.pythonhosted.org/packages/5b/0b/e45d26ccd28568013523e04f325432ea88a442b4e3020b757cf4361f0120/transformers-4.30.2-py3-none-any.whl (7.2MB)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl (268kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\varun\\anaconda3\\lib\\site-packages (from transformers) (5.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\varun\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (2021.9.30)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/90/06/1f3a3a6fb57bf3e72f63cbf0ae0991540065dd6a13393b89761b38634cb0/tokenizers-0.13.3-cp37-cp37m-win_amd64.whl (3.5MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\varun\\anaconda3\\lib\\site-packages (from transformers) (3.0.10)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/92/cc/d655b0a1d77dd3e69d1a4f354a868e5b96729cd80ee4912a6ea6fb9e2e64/safetensors-0.4.0-cp37-none-win_amd64.whl (277kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\varun\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in c:\\users\\varun\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.14.1->transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/64/f0d369ede0ca54fdd520bdee5086dbaf0af81dac53a2ce847bd1ec6e0bf1/fsspec-2023.1.0-py3-none-any.whl (143kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.10.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\varun\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.12)\n",
      "Installing collected packages: fsspec, huggingface-hub, tokenizers, safetensors, transformers\n",
      "Successfully installed fsspec-2023.1.0 huggingface-hub-0.16.4 safetensors-0.4.0 tokenizers-0.13.3 transformers-4.30.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#will need to install the transformers library. You can do this using pip\n",
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab22b4",
   "metadata": {},
   "source": [
    "### Step 2: Import Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327d2690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to import the pipeline from the transformers package.\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac2e19",
   "metadata": {},
   "source": [
    "### Step 3: Choose a Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42450e0f",
   "metadata": {},
   "source": [
    "For this example, let's use gpt-2 since it's widely known for its text generation capabilities and it's also one of the default models in the transformers library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e892674",
   "metadata": {},
   "source": [
    "### Step 4: Create a Text Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3591a963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b817eb272e046eb871199ca7228cad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\varun\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f07f999570c4baaa3323cc71da305e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f2860b21c443de9dfc857083b13e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f50ef3c3b44382a3a7a62243b8bd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52497b50d8ac491989a7333ba6b0df84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a text generation pipeline using the chosen model.\n",
    "generator = pipeline('text-generation', model='gpt2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f8538",
   "metadata": {},
   "source": [
    "### Step 5: Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011a81c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "#Now we can generate text by providing a prompt to the pipeline.\n",
    "#Here are some prompts to explore the creativity of the model\n",
    "\n",
    "prompts = [\n",
    "    \"Write a poem about the serenity of the ocean.\",\n",
    "    \"Explain the concept of black holes in layman's terms.\",\n",
    "    \"Compose a short story set in a dystopian future.\"\n",
    "    ,\"Generate a dialogue between two historical figures about modern technology.\"\n",
    "    ,\"Create a recipe for a futuristic dish.\"\n",
    "    ,\"Draft a letter from a medieval peasant to the king.\"\n",
    "    ,\"Describe a dream where the laws of physics don't apply.\"\n",
    "    ,\"Invent a myth explaining why the sun sets.\"\n",
    "    ,\"Elaborate on the feelings of a tree through the seasons.\"\n",
    "    ,\"Predict the headlines of a newspaper 100 years from now.\"\n",
    "]\n",
    "\n",
    "generated_texts = []\n",
    "for prompt in prompts:\n",
    "    result = generator(prompt, max_length=100, num_return_sequences=1, temperature = 1.0)#These Hyperparameters can be adjusted\n",
    "    generated_texts.append(result[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b088906d",
   "metadata": {},
   "source": [
    "### Step 6: Display and Analyze Generated Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34359d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1: Write a poem about the serenity of the ocean.\n",
      "\n",
      "Generated Text: Write a poem about the serenity of the ocean. It is not only a means for describing the world, but also an art – poetry as such and a way of life.\n",
      "\n",
      "To some, this means that the ocean's inhabitants are at odds with one another, or at least their minds are not united – what is their relationship with others, to the sea, the Earth?\n",
      "\n",
      "Is it a mistake to consider serenity also a way of living? Or a state of\n",
      "\n",
      "Prompt 2: Explain the concept of black holes in layman's terms.\n",
      "\n",
      "Generated Text: Explain the concept of black holes in layman's terms.\n",
      "\n",
      "What will happen if two black holes collide?\n",
      "\n",
      "First, a couple of questions have to be taken into account:\n",
      "\n",
      "Will that black hole collide with some other black hole?\n",
      "\n",
      "What kind of gravitational field is applied?\n",
      "\n",
      "So far, none of these questions have been taken directly into account. It looks almost like a theoretical answer, if you will, but the only thing that I've seen is that\n",
      "\n",
      "Prompt 3: Compose a short story set in a dystopian future.\n",
      "\n",
      "Generated Text: Compose a short story set in a dystopian future.\n",
      "\n",
      "The Dark Knight Returns\n",
      "\n",
      "Astronaut Niko Breckenridge Jameson (Chris Pine) searches for his lost self in this sleek sci-fi thriller. Based on true story.\n",
      "\n",
      "Cursed\n",
      "\n",
      "The last in a line of Chosen Ones, a New Orleans detective leads police investigating a murder. Based on a true story.\n",
      "\n",
      "Carmen Sandiego\n",
      "\n",
      "A mother's life is turned upside\n",
      "\n",
      "Prompt 4: Generate a dialogue between two historical figures about modern technology.\n",
      "\n",
      "Generated Text: Generate a dialogue between two historical figures about modern technology. The main character, a girl named Anakin Skywalker, plays a role similar to the archetypal hero of the \"Star Wars\" movies in the form of Anakin—the one who gets trapped at a party in his home on Tatooine and is rescued by a clone trooper—but one of these heroes, named Jakku, is not the hero he might be and he's also ineffectual. Instead he becomes a hero\n",
      "\n",
      "Prompt 5: Create a recipe for a futuristic dish.\n",
      "\n",
      "Generated Text: Create a recipe for a futuristic dish.\n",
      "\n",
      "The Recipe\n",
      "\n",
      "What is a dish? Basically, it is a dish that is made of a mixture of vegetables, fruit and a mixture of spices – as long as you don't burn it before it comes into contact with water.\n",
      "\n",
      "Some people might confuse this as a meal that has no calories at all. This is not the case. Cooking it and serving it up is the essence of being a great cook.\n",
      "\n",
      "Some may even\n",
      "\n",
      "Prompt 6: Draft a letter from a medieval peasant to the king.\n",
      "\n",
      "Generated Text: Draft a letter from a medieval peasant to the king. This is the first step to a full restoration and restoration of your freedom, to have your freedom to pursue education and life with dignity. If you want to be a monk or nun, then you may apply for the full restoration of your freedom. That right is very real.\"\n",
      "\n",
      "Fang says that monks, nuns and laypeople can live their lives in a society where they have full freedom and who can serve as an educator and spiritual leader\n",
      "\n",
      "Prompt 7: Describe a dream where the laws of physics don't apply.\n",
      "\n",
      "Generated Text: Describe a dream where the laws of physics don't apply. In the next article, we'll show you how we got there!\n",
      "\n",
      "About \"Famous Robots\" Inventor, Inventor of \"Star Wars, Aliens\"\n",
      "\n",
      "In this article, we'll share some inspiring inventions and discover how engineers developed them, making them something more:\n",
      "\n",
      "What is a \"Famous Robot\"?\n",
      "\n",
      "When scientists think of the term \"bot\", they tend to think of robots\n",
      "\n",
      "Prompt 8: Invent a myth explaining why the sun sets.\n",
      "\n",
      "Generated Text: Invent a myth explaining why the sun sets.\n",
      "\n",
      "Why was a solar eclipse such a big deal in the first place? A couple of things, you'll come across before:\n",
      "\n",
      "Some eclipse fans didn't recognize it.\n",
      "\n",
      "A few of the best ones:\n",
      "\n",
      "NASA recently announced a team of astrophysicists at Caltech of a team developing one of the most accurate celestial alignments known to man. The team, led by University of Alberta astrophysicist David B\n",
      "\n",
      "Prompt 9: Elaborate on the feelings of a tree through the seasons.\n",
      "\n",
      "Generated Text: Elaborate on the feelings of a tree through the seasons.\n",
      "\n",
      "Prompt 10: Predict the headlines of a newspaper 100 years from now.\n",
      "\n",
      "Generated Text: Predict the headlines of a newspaper 100 years from now.\n",
      "\n",
      "No, I am not suggesting that that will happen. But, if it does, perhaps it won´t be long before people are making a concerted effort in this respect, as they now do in reading about events in Russia. Even before this first-person event, Putin's approval ratings were at their lowest level since the early 20th century. This change will probably have something to do with what happens next, when it´\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Displaying the generated responses for the prompts\n",
    "\n",
    "for i, text in enumerate(generated_texts):\n",
    "    print(f\"Prompt {i+1}: {prompts[i]}\\n\")\n",
    "    print(f\"Generated Text: {text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312278d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f4a632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2aae9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "#Adjusting the hyperparameters and observing the responses\n",
    "\n",
    "generated_texts = []\n",
    "for prompt in prompts:\n",
    "    result = generator(prompt, max_length=100, num_return_sequences=1, temperature = 0.9)\n",
    "    generated_texts.append(result[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a434b24e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1: Write a poem about the serenity of the ocean.\n",
      "\n",
      "Generated Text: Write a poem about the serenity of the ocean.\n",
      "\n",
      "As my soul grew, I was reminded—now more than ever—of the ocean.\n",
      "\n",
      "The ocean is here, though it is all there is.\n",
      "\n",
      "\n",
      "It's all here—a world of water—a world-wide sea of dreams.\n",
      "\n",
      "\n",
      "There's no ocean left, no land left to wander; nothing to do but run, to swim…\n",
      "\n",
      "\n",
      "The sun's all gone, nothing to do\n",
      "\n",
      "Prompt 2: Explain the concept of black holes in layman's terms.\n",
      "\n",
      "Generated Text: Explain the concept of black holes in layman's terms.\n",
      "\n",
      "The scientific world is divided into two categories. In the first category, all black holes are black. In the second category, the black hole is just dark matter in general. This, together with their enormous size, means that black holes are essentially invisible, because they are just dark matter.\n",
      "\n",
      "We may also know that black holes do have the ability to create small \"black holes\" in the cosmos. The dark matter\n",
      "\n",
      "Prompt 3: Compose a short story set in a dystopian future.\n",
      "\n",
      "Generated Text: Compose a short story set in a dystopian future. I like the ending and you want to get the sense that you want it to be a dystopian story. I feel as if we're dealing with a rather grim tone. Is anyone going to notice?\n",
      "\n",
      "I'm doing the story and it's a lot more gritty than the last one. I'm kind of taking advantage of my own experiences as well. That was the main takeaway. I didn't feel like I was able to do anything\n",
      "\n",
      "Prompt 4: Generate a dialogue between two historical figures about modern technology.\n",
      "\n",
      "Generated Text: Generate a dialogue between two historical figures about modern technology. The dialogue may have several variations, and sometimes have to do with what's happened in the past. The earliest recorded text on this topic is the Book of Mormon.\n",
      "\n",
      "The second-most famous text on this topic, and one that has received very little scholarly attention and has been extensively studied since the early 19th century, is the Book of Mormon. These books were written by Aaron, King of Israel, and some of the younger\n",
      "\n",
      "Prompt 5: Create a recipe for a futuristic dish.\n",
      "\n",
      "Generated Text: Create a recipe for a futuristic dish.\n",
      "\n",
      "And then, using your hands, you can turn the dial. Now, let's explore that menu, to see what's out there, and what we can be sure of.\n",
      "\n",
      "1. Get a taste of all the flavors\n",
      "\n",
      "The real challenge: find every flavor. If you have a good palate, if you can get the right ingredients, if you want more than just taste, then you're going to have an amazing dish.\n",
      "\n",
      "Prompt 6: Draft a letter from a medieval peasant to the king.\n",
      "\n",
      "Generated Text: Draft a letter from a medieval peasant to the king.\n",
      "\n",
      "\"I don't know, I don't think I'll ever remember you, nor do we have a son or a nephew,\" he said.\n",
      "\n",
      "His father's death, the \"fantastic death of a person's life and identity,\" the letter read, \"made such a difference to the life and person of this generation.\"\n",
      "\n",
      "\"It is an immense privilege that the Lord's life can be preserved in this country\n",
      "\n",
      "Prompt 7: Describe a dream where the laws of physics don't apply.\n",
      "\n",
      "Generated Text: Describe a dream where the laws of physics don't apply. The second part of the story, titled What is Reality?, explains that there is no law of physics that would allow for the creation of an artificial mind or a computer. As in the previous two stories, the story is an allegory for the possibility of the creation of the universe and that it could happen under the constraints of gravity that we have yet to see. The title for this theme, \"Sensory Imitation,\" is\n",
      "\n",
      "Prompt 8: Invent a myth explaining why the sun sets.\n",
      "\n",
      "Generated Text: Invent a myth explaining why the sun sets. If it's not the sun, can you think of anything that is more likely to produce a sun to set it?\n",
      "\n",
      "I've been told by some people that they are never sure. What seems unlikely is that it's not the sun and it's not the wind that is the cause. The sun doesn't cause thunder or hurricanes when they're high in altitude, even though it is the sun. They know that they will be getting high\n",
      "\n",
      "Prompt 9: Elaborate on the feelings of a tree through the seasons.\n",
      "\n",
      "Generated Text: Elaborate on the feelings of a tree through the seasons.\n",
      "\n",
      "[Image by: Robert J. Stokes]\n",
      "\n",
      "Prompt 10: Predict the headlines of a newspaper 100 years from now.\n",
      "\n",
      "Generated Text: Predict the headlines of a newspaper 100 years from now. In the decades since that time, the world has been divided into three different \"civilizations\": the U.S., the Soviet Union, China and India. The former is dominated by an anti-American, pro-Western, pro-Christian, anti-communist faction in the West that is hostile to the interests of the U.S. and Israel. The latter is dominated by a religious faction in the West that is hostile to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Dipslaying new responses with new hyperparameters and observing the difference\n",
    "for i, text in enumerate(generated_texts):\n",
    "    print(f\"Prompt {i+1}: {prompts[i]}\\n\")\n",
    "    print(f\"Generated Text: {text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67966674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
